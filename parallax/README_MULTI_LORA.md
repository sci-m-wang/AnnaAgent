# Parallax å¤š LoRA æœåŠ¡ä½¿ç”¨æŒ‡å—

## ğŸ‰ å¥½æ¶ˆæ¯!

**Parallax æ”¯æŒåœ¨å•ä¸ªå®ä¾‹ä¸­åŠ è½½å¤šä¸ª LoRA adapters!**

ä½ **ä¸éœ€è¦**å¯åŠ¨å¤šä¸ªå®ä¾‹,åªéœ€:
1. å¯åŠ¨ä¸€ä¸ª Parallax å®ä¾‹
2. åŒæ—¶æ³¨å†Œå¤šä¸ª LoRA adapters
3. åœ¨è¯·æ±‚æ—¶é€šè¿‡ `model` å‚æ•°åŠ¨æ€é€‰æ‹©ä½¿ç”¨å“ªä¸ª LoRA

è¿™æ¯”ä¹‹å‰çš„å¤šå®ä¾‹æ–¹æ¡ˆ**æ›´é«˜æ•ˆã€æ›´èŠ‚çœèµ„æº**!

---

## ğŸ“¦ æ–‡ä»¶è¯´æ˜

### æ¨èæ–¹æ¡ˆ (å•å®ä¾‹å¤š LoRA)

- **`start_multi_lora.sh`** - Bash å¯åŠ¨è„šæœ¬ (å•å®ä¾‹)
- **`start_multi_lora.py`** - Python å¯åŠ¨è„šæœ¬ (å•å®ä¾‹,æ¨è)
- **`client_example.py`** - Python å®¢æˆ·ç«¯ç¤ºä¾‹ä»£ç 

### å¤‡é€‰æ–¹æ¡ˆ (å¤šå®ä¾‹,ä¸æ¨è)

- **`start_multi_models.sh`** - Bash å¯åŠ¨è„šæœ¬ (å¤šå®ä¾‹)
- **`start_multi_models.py`** - Python å¯åŠ¨è„šæœ¬ (å¤šå®ä¾‹)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å¯åŠ¨æœåŠ¡

```bash
# ä½¿ç”¨ Python è„šæœ¬ (æ¨è)
python3 start_multi_lora.py

# æˆ–ä½¿ç”¨ Bash è„šæœ¬
./start_multi_lora.sh
```

### 2. æœåŠ¡é…ç½®

å¯åŠ¨å,æœåŠ¡ä¼š:
- åŠ è½½åŸºç¡€æ¨¡å‹: `Qwen/Qwen2.5-7B-Instruct`
- æ³¨å†Œä¸¤ä¸ª LoRA adapters:
  - `emotion`: æƒ…ç»ªæ¨ç†æ¨¡å‹
  - `chief`: ä¸»è¯‰é“¾è·¯ç”Ÿæˆæ¨¡å‹
- ç›‘å¬ç«¯å£: `3000`

### 3. è°ƒç”¨ API

é€šè¿‡ `model` å‚æ•°é€‰æ‹©ä½¿ç”¨å“ªä¸ª LoRA:

```bash
# ä½¿ç”¨æƒ…ç»ªæ¨ç† LoRA
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "emotion",
    "messages": [{"role": "user", "content": "æˆ‘ä»Šå¤©å¾ˆå¼€å¿ƒ"}],
    "max_tokens": 512
  }'

# ä½¿ç”¨ä¸»è¯‰é“¾è·¯ç”Ÿæˆ LoRA
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "chief",
    "messages": [{"role": "user", "content": "æ‚£è€…ä¸»è¯‰å¤´ç—›"}],
    "max_tokens": 1024
  }'

# ä½¿ç”¨åŸºç¡€æ¨¡å‹ (ä¸æŒ‡å®š model)
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "ä½ å¥½"}],
    "max_tokens": 512
  }'
```

---

## ğŸ Python å®¢æˆ·ç«¯

### åŸºç¡€ä½¿ç”¨

```python
from client_example import ParallaxClient

client = ParallaxClient()

# æƒ…ç»ªæ¨ç†
result = client.emotion_inference("æˆ‘ä»Šå¤©å¿ƒæƒ…å¾ˆå¥½")
print(result)

# ä¸»è¯‰é“¾è·¯ç”Ÿæˆ
result = client.chief_chain_generation("æ‚£è€…ä¸»è¯‰å¤´ç—›")
print(result)

# åŸºç¡€æ¨¡å‹
result = client.base_chat("ä½ å¥½")
print(result)
```

### è¿è¡Œç¤ºä¾‹ä»£ç 

```bash
python3 client_example.py
```

ç¤ºä¾‹ä»£ç åŒ…å«:
- âœ… åŸºç¡€ä½¿ç”¨
- âœ… æµå¼è¾“å‡º
- âœ… å¤šè½®å¯¹è¯
- âœ… æ‰¹é‡å¤„ç†
- âœ… å‚æ•°é…ç½®
- âœ… é”™è¯¯å¤„ç†

---

## ğŸ”§ é«˜çº§é…ç½®

### æ·»åŠ æ›´å¤š LoRA

ç¼–è¾‘ `start_multi_lora.py`:

```python
LORA_ADAPTERS = {
    "emotion": "sci-m-wang/Emotion_inferencer-Qwen2.5-7B-Instruct",
    "chief": "sci-m-wang/Chief_chain_generator-Qwen2.5-7B-Instruct",
    "your_lora": "your-huggingface-id/your-lora-model",  # æ·»åŠ æ–°çš„
}
```

### è°ƒæ•´ LoRA ç¼“å­˜ç­–ç•¥

åœ¨å¯åŠ¨è„šæœ¬ä¸­ä¿®æ”¹:

```bash
--max-loras-per-batch 8      # åŒä¸€æ‰¹æ¬¡æœ€å¤šä½¿ç”¨çš„ LoRA æ•°é‡
--max-loaded-loras 8         # å†…å­˜ä¸­æœ€å¤šåŠ è½½çš„ LoRA æ•°é‡
--lora-eviction-policy lru   # æ·˜æ±°ç­–ç•¥: lru æˆ– fifo
```

### ä½¿ç”¨æœ¬åœ° LoRA

å¦‚æœå·²ä¸‹è½½åˆ°æœ¬åœ°:

```python
LORA_ADAPTERS = {
    "emotion": "/path/to/local/emotion-lora",
    "chief": "/path/to/local/chief-lora",
}
```

---

## ğŸ’¡ å·¥ä½œåŸç†

### LoRA åŠ¨æ€åŠ è½½

```
è¯·æ±‚æµç¨‹:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å®¢æˆ·ç«¯è¯·æ±‚ (model="emotion")            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Parallax æ£€æŸ¥ LoRA ç¼“å­˜                 â”‚
â”‚ - å¦‚æœå·²åŠ è½½: ç›´æ¥ä½¿ç”¨                  â”‚
â”‚ - å¦‚æœæœªåŠ è½½: ä»ç£ç›˜/HF åŠ è½½            â”‚
â”‚ - å¦‚æœç¼“å­˜æ»¡: æŒ‰ LRU ç­–ç•¥æ·˜æ±°           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ åŸºç¡€æ¨¡å‹ + emotion LoRA â†’ æ¨ç†         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ è¿”å›ç»“æœ                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ‰¹å¤„ç†æ”¯æŒ

Parallax æ”¯æŒåœ¨**åŒä¸€æ‰¹æ¬¡**ä¸­å¤„ç†ä½¿ç”¨**ä¸åŒ LoRA** çš„è¯·æ±‚:

```python
# è¯·æ±‚ 1: ä½¿ç”¨ emotion LoRA
# è¯·æ±‚ 2: ä½¿ç”¨ chief LoRA
# è¯·æ±‚ 3: ä¸ä½¿ç”¨ LoRA (åŸºç¡€æ¨¡å‹)

# è¿™ä¸‰ä¸ªè¯·æ±‚å¯ä»¥åœ¨åŒä¸€æ‰¹æ¬¡ä¸­å¤„ç†!
# max-loras-per-batch æ§åˆ¶æ‰¹æ¬¡ä¸­æœ€å¤šæœ‰å¤šå°‘ä¸ªä¸åŒçš„ LoRA
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| æ–¹æ¡ˆ | å†…å­˜å ç”¨ | å¯åŠ¨æ—¶é—´ | åˆ‡æ¢å»¶è¿Ÿ | èµ„æºåˆ©ç”¨ |
|------|---------|---------|---------|---------|
| **å•å®ä¾‹å¤š LoRA** | ~8GB | ~30s | <100ms | â­â­â­â­â­ |
| å¤šå®ä¾‹ | ~24GB | ~90s | 0ms | â­â­ |

**æ¨èä½¿ç”¨å•å®ä¾‹å¤š LoRA æ–¹æ¡ˆ!**

---

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### 1. å¤šä¸“å®¶ç³»ç»Ÿ

```python
# ä¸åŒä»»åŠ¡ä½¿ç”¨ä¸åŒçš„ä¸“å®¶æ¨¡å‹
emotion_result = client.emotion_inference(text)
chief_result = client.chief_chain_generation(text)
summary_result = client.chat(messages, model="summary")
```

### 2. A/B æµ‹è¯•

```python
# æµ‹è¯•ä¸åŒç‰ˆæœ¬çš„ LoRA
result_v1 = client.chat(messages, model="emotion_v1")
result_v2 = client.chat(messages, model="emotion_v2")
```

### 3. æ™ºèƒ½è·¯ç”±

```python
# æ ¹æ®ä»»åŠ¡ç±»å‹è‡ªåŠ¨é€‰æ‹©æ¨¡å‹
def smart_route(task_type, text):
    if task_type == "emotion":
        return client.emotion_inference(text)
    elif task_type == "medical":
        return client.chief_chain_generation(text)
    else:
        return client.base_chat(text)
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### å†…å­˜ç®¡ç†

- æ¯ä¸ª LoRA adapter å ç”¨é¢å¤–å†…å­˜ (é€šå¸¸ <500MB)
- `max-loaded-loras` é™åˆ¶å†…å­˜ä¸­åŒæ—¶åŠ è½½çš„ LoRA æ•°é‡
- è¶…è¿‡é™åˆ¶æ—¶,æŒ‰ LRU ç­–ç•¥è‡ªåŠ¨å¸è½½

### é¦–æ¬¡åŠ è½½å»¶è¿Ÿ

- ç¬¬ä¸€æ¬¡ä½¿ç”¨æŸä¸ª LoRA æ—¶éœ€è¦ä»ç£ç›˜/ç½‘ç»œåŠ è½½
- åç»­è¯·æ±‚ä¼šå‘½ä¸­ç¼“å­˜,å»¶è¿Ÿå¾ˆä½
- å¯ä»¥é¢„çƒ­å¸¸ç”¨çš„ LoRA

### æ‰¹å¤„ç†é™åˆ¶

- `max-loras-per-batch` é™åˆ¶å•æ‰¹æ¬¡ä¸­ä¸åŒ LoRA çš„æ•°é‡
- è¶…è¿‡é™åˆ¶æ—¶,è¯·æ±‚ä¼šè¢«åˆ†åˆ°ä¸åŒæ‰¹æ¬¡
- å»ºè®®è®¾ç½®ä¸ºå¸¸ç”¨ LoRA æ•°é‡

---

## ğŸ” æ•…éšœæ’æŸ¥

### 1. LoRA åŠ è½½å¤±è´¥

```bash
# æ£€æŸ¥æ—¥å¿—
tail -f parallax_logs/server.log

# å¸¸è§åŸå› :
# - LoRA è·¯å¾„é”™è¯¯
# - ç½‘ç»œé—®é¢˜ (HuggingFace ä¸‹è½½)
# - LoRA ä¸åŸºç¡€æ¨¡å‹ä¸å…¼å®¹
```

### 2. å†…å­˜ä¸è¶³

```bash
# å‡å°‘ max-loaded-loras
--max-loaded-loras 4  # ä» 8 é™åˆ° 4

# æˆ–å‡å°‘æ‰¹å¤„ç†å¤§å°
--max-batch-size 4  # ä» 8 é™åˆ° 4
```

### 3. æ¨¡å‹æœªæ‰¾åˆ°

```bash
# ç¡®ä¿è¯·æ±‚ä¸­çš„ model åç§°ä¸æ³¨å†Œçš„ LoRA åç§°ä¸€è‡´
# æ³¨å†Œ: "emotion=$LORA_EMOTION"
# è¯·æ±‚: "model": "emotion"  âœ…
# è¯·æ±‚: "model": "Emotion"  âŒ (å¤§å°å†™æ•æ„Ÿ)
```

---

## ğŸ“š API å‚è€ƒ

### è¯·æ±‚æ ¼å¼

```json
{
  "model": "emotion",           // LoRA åç§° (å¯é€‰)
  "messages": [                 // æ¶ˆæ¯åˆ—è¡¨
    {"role": "user", "content": "..."}
  ],
  "max_tokens": 512,            // æœ€å¤§ç”Ÿæˆ token æ•°
  "temperature": 0.7,           // æ¸©åº¦å‚æ•° (0.0-2.0)
  "top_p": 0.9,                 // nucleus sampling
  "stream": false               // æ˜¯å¦æµå¼è¾“å‡º
}
```

### å“åº”æ ¼å¼

```json
{
  "id": "req-xxx",
  "object": "chat.completion",
  "model": "emotion",
  "created": 1234567890,
  "choices": [{
    "index": 0,
    "message": {
      "role": "assistant",
      "content": "..."
    },
    "finish_reason": "eos"
  }],
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 20,
    "total_tokens": 30
  }
}
```

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Request!

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®ä½¿ç”¨ Apache-2.0 è®¸å¯è¯ã€‚

---

## ğŸ™ è‡´è°¢

- [Parallax](https://github.com/GradientHQ/parallax) - åˆ†å¸ƒå¼ LLM æ¨ç†æ¡†æ¶
- [SGLang](https://github.com/sgl-project/sglang) - GPU åç«¯
- [Qwen](https://huggingface.co/Qwen) - åŸºç¡€æ¨¡å‹

---

**ç¥ä½¿ç”¨æ„‰å¿«! ğŸ‰**
